[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sophie Nguyen",
    "section": "",
    "text": "Welcome to my personal website.\nI am Sophie, a data scientist. I love working with data, finding insights, generating forecasts, and forming practical recommendations."
  },
  {
    "objectID": "projects/intro.html",
    "href": "projects/intro.html",
    "title": "Projects",
    "section": "",
    "text": "Individual projects\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nProject code test\n\n\nSome project description\n\n\n\nSophie Nguyen\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "productivity/code_sklearn_basics.html",
    "href": "productivity/code_sklearn_basics.html",
    "title": "Sophie Nguyen",
    "section": "",
    "text": "Data processing - features\n\nNumerical inputs\nCategorical inputs\n\nData processing - output\nModel selection with gridsearch\nFinal model object\nModel performance\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.datasets import make_circles, make_classification, make_moons\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nnames = [\n    \"Nearest Neighbors\",\n    \"Linear SVM\",\n    \"RBF SVM\",\n    \"Gaussian Process\",\n    \"Decision Tree\",\n    \"Random Forest\",\n    \"Neural Net\",\n    \"AdaBoost\",\n    \"Naive Bayes\",\n    \"QDA\",\n]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025, random_state=42),\n    SVC(gamma=2, C=1, random_state=42),\n    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n    DecisionTreeClassifier(max_depth=5, random_state=42),\n    RandomForestClassifier(\n        max_depth=5, n_estimators=10, max_features=1, random_state=42\n    ),\n    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n    AdaBoostClassifier(random_state=42),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n]\n\n\nX, y = make_classification(\n    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n)\nrng = np.random.RandomState(2)\nX += 2 * rng.uniform(size=X.shape)\nlinearly_separable = (X, y)\n\ndatasets = [\n    make_moons(noise=0.3, random_state=0),\n    make_circles(noise=0.2, factor=0.5, random_state=1),\n    linearly_separable,\n]\n\n\nfigure = plt.figure(figsize=(27, 9))\ni = 1\n# iterate over datasets\nfor ds_cnt, ds in enumerate(datasets):\n    # preprocess dataset, split into training and test part\n    X, y = ds\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.4, random_state=42\n    )\n\n    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n\n    # just plot the dataset first\n    cm = plt.cm.RdBu\n    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n    if ds_cnt == 0:\n        ax.set_title(\"Input data\")\n    # Plot the training points\n    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n    # Plot the testing points\n    ax.scatter(\n        X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n    )\n    ax.set_xlim(x_min, x_max)\n    ax.set_ylim(y_min, y_max)\n    ax.set_xticks(())\n    ax.set_yticks(())\n    i += 1\n\n    # iterate over classifiers\n    for name, clf in zip(names, classifiers):\n        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n\n        clf = make_pipeline(StandardScaler(), clf)\n        clf.fit(X_train, y_train)\n        score = clf.score(X_test, y_test)\n        DecisionBoundaryDisplay.from_estimator(\n            clf, X, cmap=cm, alpha=0.8, ax=ax, eps=0.5\n        )\n\n        # Plot the training points\n        ax.scatter(\n            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n        )\n        # Plot the testing points\n        ax.scatter(\n            X_test[:, 0],\n            X_test[:, 1],\n            c=y_test,\n            cmap=cm_bright,\n            edgecolors=\"k\",\n            alpha=0.6,\n        )\n\n        ax.set_xlim(x_min, x_max)\n        ax.set_ylim(y_min, y_max)\n        ax.set_xticks(())\n        ax.set_yticks(())\n        if ds_cnt == 0:\n            ax.set_title(name)\n        ax.text(\n            x_max - 0.3,\n            y_min + 0.3,\n            (\"%.2f\" % score).lstrip(\"0\"),\n            size=15,\n            horizontalalignment=\"right\",\n        )\n        i += 1\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "productivity/intro.html",
    "href": "productivity/intro.html",
    "title": "Productivity",
    "section": "",
    "text": "Idea, tools, and code templates to help jump-start a modeling project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA documentation template for machine learning model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "productivity/hello.html",
    "href": "productivity/hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "productivity/documentation_ml_basics.html",
    "href": "productivity/documentation_ml_basics.html",
    "title": "A documentation template for machine learning model",
    "section": "",
    "text": "The business context around the project\nUsages of the project target\n\nThe scope of the project such as only applicable to selected lines of business or product groups\n\nExisting process\n\nProblems/concerns with the current process\nPerformance of the current process\n\nExpectations of the project deliveries\nEvaluation metrics of the project outcomes\nUpstream/Downstream tools and models"
  },
  {
    "objectID": "productivity/documentation_ml_basics.html#modeling",
    "href": "productivity/documentation_ml_basics.html#modeling",
    "title": "A documentation template for machine learning model",
    "section": "Modeling",
    "text": "Modeling\n\nConceptual model or guidances from subject-matter experts (SMEs)\n\nIdeas and business process theory recommended by SMEs\n\nDefine of the model target/outcome\nDefine of the observational unit\nGuide the process of looking for useful data sources\nProvide some guidance about sensible or expected relationships among features or with the target\n\nThe context or subject journey that can affect the target of interest\n\n\n\nData\n\nList and short descriptions of all data sources used.\nData processing notes\n\nDefine the model target/outcome in clear technical definition (if needed to be created)\nDescribe the data processing pipeline\n\nTrain and test set splitting process\n\n\n\nData insights\n\nDescription of the training data period/sample\n\nCounts\nTime period if there is a time dimension\n\nSummary and highlights about the target\n\nDistribution\nMissingness\n\nSummary and highlights about the independent variables\n\nDistribution\nMissingness\n\nAny features generated and why\nAny key potential (predictive) relationships among features and with the target\n\n\n\nModel methodology\n\nA summary of the model ethology\nCitations to the theoretical models\nModels tested\nModel selection\nVariable selection\nHyper-parameter tuning\n\n\n\nModel diagnostics\n\nFeature importance\nTraining errors\n\nError distribution\n\nQQ-plot\n\nEvaluation metrics\nError versus predicted\nError versus actual\nError versus key features\nErrors versus time/index (if autocorrelation is a suspected)\n\n\n\n\nModel interpretability\n\nModel predictions for selected profiles"
  },
  {
    "objectID": "productivity/documentation_ml_basics.html#model-implementation",
    "href": "productivity/documentation_ml_basics.html#model-implementation",
    "title": "A documentation template for machine learning model",
    "section": "Model implementation",
    "text": "Model implementation\n\nData input\n\nList all the data sources needed to provide data inputs for model run\nSummary of any concerns about data gaps between training and production environment ### Production environment\nDiagram or description of the production pipeline\nBack-up plan for model failures\n\n\n\nModel production\n\nA summary of the model production process and all inputs needed.\nThe documentation should be sufficient for an independent ML Ops team to be able to put the model into production with minimal in-person guidance."
  },
  {
    "objectID": "productivity/documentation_ml_basics.html#model-monitoring-and-maintenance",
    "href": "productivity/documentation_ml_basics.html#model-monitoring-and-maintenance",
    "title": "A documentation template for machine learning model",
    "section": "Model monitoring and maintenance",
    "text": "Model monitoring and maintenance\n\nModel monitoring\n\nMonitoring metrics\nThresholds and actions recommended, for example\n\nIf RMSE is below the lowest threshold, no action needed\nIf RMSE is above the lowest threshold, investigate the cause\nIf RMSE goes over certain levels, immediately stop the model in production and move to back-up plan\n\n\n\n\nModel automatic update/retraining schedule\n\nProduction setup to support automatic training\n\nTest set evaluation\nCompare current versus new model\n\nAnalysis results supported this automatic updating schedule"
  }
]